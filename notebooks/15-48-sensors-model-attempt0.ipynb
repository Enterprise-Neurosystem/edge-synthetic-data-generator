{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea6162fe-96d2-48c9-9cd0-27a8863333d1",
   "metadata": {},
   "source": [
    "https://github.com/gretelai/gretel-synthetics/blob/master/examples/timeseries_dgan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628f5e1-5982-4b89-b170-65205f2b7ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# version recommended by source\n",
    "!pip install torch==1.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfe71ee-35f0-458f-a15b-d40e81e21cd0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/gretelai/gretel-synthetics.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3144226a-f7df-4bc4-85c3-410679af5d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch\n",
    "\n",
    "from gretel_synthetics.timeseries_dgan.dgan import DGAN\n",
    "from gretel_synthetics.timeseries_dgan.config import DGANConfig, OutputType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc758cca-a4bc-4c54-bfed-b960a44d05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/xiaxiaxu/predictmachinefailureinadvance/data\n",
    "sensor = pd.read_csv(\"sensor.csv\")\n",
    "sensor.isnull().sum()\n",
    "COLS_TO_DROP = [\"Unnamed: 0\", \"sensor_00\", \"sensor_15\", \"sensor_50\", \"sensor_51\"]\n",
    "sensor.drop(COLS_TO_DROP, axis=1, inplace=True)\n",
    "\n",
    "print(sensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38af530-7af6-4c96-aa48-172334398948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets convert our datatypes to the correct ones\n",
    "print(sensor.dtypes, \"\\n\")\n",
    "# i have no idea why i have to run this line twice for it to work.\n",
    "sensor[\"timestamp\"] = pd.to_datetime(sensor[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100795fe-cef4-4f3b-9df3-935f201dadf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many NaN rows do we have?\n",
    "print(len(sensor[sensor.isna().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7021da9d-37df-4a40-a035-6933b6a03a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets drop them\n",
    "sensor.dropna(axis=0, inplace=True)\n",
    "print(len(sensor[sensor.isna().any(axis=1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1975505-a81a-4762-8125-7c6bdebb697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets try only using data centered around 2 failures.\n",
    "data_around_failures = sensor.iloc[16000:26080]\n",
    "print(len(data_around_failures))\n",
    "data_around_failures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829c5d8e-38fb-4604-b2f0-0dabab740f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplot matrix\n",
    "fig, axes = plt.subplots(10, 5, figsize=(20, 20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for col, ax in zip(sensor.columns[1:-1], axes.flat):\n",
    "    sensor[col].plot.line(ax=ax)\n",
    "    ax.set_title(col)\n",
    "# disable leftover axes\n",
    "for ax in axes.flat[sensor.columns[1:-1].size :]:\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2241974-62bb-4bcd-b938-107e21401747",
   "metadata": {},
   "source": [
    "okay, scaling sanity check passed. lets start splitting the data to prepare it for training in dGAN.\n",
    "\n",
    "NOTE: data generated will be in the shape of data passed in for training. so if we pass in samples of 10 rows per, it will only generate a sample of 10 rows.\n",
    "\n",
    "we have 10,080 rows of data now, which corresponds to 10,080 minutes of data = 168 hours of data = 7 days of data.\n",
    "\n",
    "I'm going to try splitting the data into two hour segments - giving us 84 120row/minute readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c743f171-ded4-47c9-ba61-90d82319192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping timestamp and machine_status columns\n",
    "data_around_failures.drop([\"timestamp\", \"machine_status\"], axis=1, inplace=True)\n",
    "features = data_around_failures.to_numpy()\n",
    "print(features.shape)\n",
    "\n",
    "# number of samples to split into\n",
    "n = features.shape[0] // 120\n",
    "print(n)\n",
    "\n",
    "# reshape the data accordingly\n",
    "features = features[: (n * 120), :].reshape(-1, 120, features.shape[1])\n",
    "# Shape is now (# examples, # time points, # features)\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e6261-714c-4a63-9c07-ecf79f826c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended to train with a GPU - am not for now.\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69d93d-66d2-4888-8828-bb6eae9fa9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up DGAN config.\n",
    "config = DGANConfig(\n",
    "    max_sequence_len=features.shape[1],\n",
    "    sample_len=12,\n",
    "    batch_size=min(1000, features.shape[0]),\n",
    "    apply_feature_scaling=True,  # already scaled\n",
    "    apply_example_scaling=False,\n",
    "    use_attribute_discriminator=False,\n",
    "    generator_learning_rate=1e-4,\n",
    "    discriminator_learning_rate=1e-4,\n",
    "    epochs=10000,\n",
    ")\n",
    "\n",
    "model = DGAN(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca8415-f802-42ce-91f9-638c8d6aaa56",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.train_numpy(\n",
    "    features,\n",
    "    feature_types=[OutputType.CONTINUOUS] * features.shape[2],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150da97-1b52-4c27-b87e-1e2d4161187b",
   "metadata": {},
   "source": [
    "finished training at around 6-7 mins on large notebook image - not bad! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68bca9c-66c7-4b8a-947b-b98fa4bc7fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data - this ran near instantly\n",
    "_, synthetic_features = model.generate_numpy(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4c7ea-3c51-4bff-99b5-6544dcaedba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weak correlations between synthetic and real data\n",
    "sensor_cols = data_around_failures.columns\n",
    "synthetic_df = pd.DataFrame(\n",
    "    synthetic_features.reshape(-1, synthetic_features.shape[2]), columns=sensor_cols\n",
    ")\n",
    "data_around_failures.reset_index(inplace=True)\n",
    "data_around_failures.corrwith(synthetic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bb8b9-7a53-4d0a-8b7b-dd21325f7215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mutlicorrelation seems to be a problem in both the real and synthetic data;\n",
    "# but at least this means that the synthetic data is mimicing the real data well.\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 5))\n",
    "sns.heatmap(data_around_failures.corr(), cmap=\"Greens\", ax=ax1)\n",
    "sns.heatmap(synthetic_df.corr(), cmap=\"Blues\", ax=ax2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5b54c-3782-4af9-be1c-93678e59306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot matrix for synthetic sensor data\n",
    "\n",
    "fig, axes = plt.subplots(10, 5, figsize=(20, 20))\n",
    "fig.tight_layout()\n",
    "\n",
    "for col, ax in zip(synthetic_df.columns, axes.flat):\n",
    "    synthetic_df[col].plot.line(ax=ax)\n",
    "    ax.set_title(col)\n",
    "# disable leftover axes\n",
    "for ax in axes.flat[synthetic_df.columns.size :]:\n",
    "    ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacab6de-0b7b-41e8-8cee-f0c32640e626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of sensor_34 values\n",
    "\n",
    "plt.hist(\n",
    "    [data_around_failures[\"sensor_34\"], synthetic_df[\"sensor_34\"]],\n",
    "    label=[\"real\", \"synthetic\"],\n",
    "    bins=25,\n",
    "    density=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sensor 34 Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4f264-0223-4396-b5c7-7fec27e12260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of sensor_25 values\n",
    "\n",
    "plt.hist(\n",
    "    [data_around_failures[\"sensor_25\"], synthetic_df[\"sensor_25\"]],\n",
    "    label=[\"real\", \"synthetic\"],\n",
    "    bins=25,\n",
    "    density=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sensor 25 Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0e1636-c2f6-4855-8203-618126d0bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of sensor_11 values\n",
    "\n",
    "plt.hist(\n",
    "    [data_around_failures[\"sensor_11\"], synthetic_df[\"sensor_11\"]],\n",
    "    label=[\"real\", \"synthetic\"],\n",
    "    bins=25,\n",
    "    density=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sensor 11 Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfc9889-8551-4d31-b624-ab29892a730e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distribution of sensor_36 values\n",
    "\n",
    "plt.hist(\n",
    "    [data_around_failures[\"sensor_36\"], synthetic_df[\"sensor_36\"]],\n",
    "    label=[\"real\", \"synthetic\"],\n",
    "    bins=25,\n",
    "    density=True,\n",
    ")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Sensor 36 Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343ff8a5-d321-42ab-bcb0-a201fc9564f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model for future use\n",
    "model.save(\"dgan_model_3_48_sensors.pt\")\n",
    "\n",
    "# X = model.load(\"dgan_model_3_48_sensors.pt\")\n",
    "\n",
    "# X"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
