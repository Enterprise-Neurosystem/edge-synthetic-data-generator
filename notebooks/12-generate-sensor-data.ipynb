{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8360a285-10f9-43ff-ab16-146adfbd1bbc",
   "metadata": {},
   "source": [
    "# Generate Sensor Data\n",
    "\n",
    "In this notebook, we will generate synthetic data from a model trained on our real sensor data. \n",
    "\n",
    "We use an open-source implementation by Gretel AI found [here](https://github.com/gretelai/gretel-synthetics) of the generative adversarial network known as DoppelGANger. For more information on DoppelGANger, see the [paper](http://arxiv.org/abs/1909.13403) and the respective GitHub [repository](https://github.com/fjxmlzn/DoppelGANger).\n",
    "\n",
    "We are generating data based on preexisting public water pump sensor data, found on [kaggle](https://www.kaggle.com/code/xiaxiaxu/predictmachinefailureinadvance/data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e826d-0bdd-4fcf-80ac-1f5e9aa93515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# first, pip installs to ensure we have the correct packages\n",
    "\n",
    "!pip install torch==1.11.0  # version recommended by source\n",
    "#!pip install git+https://github.com/gretelai/gretel-synthetics.git\n",
    "!pip install -U gretel-synthetics==0.19.0\n",
    "!pip install numpy==1.20.0  # for new concatenate feature\n",
    "!pip install kafka-python==2.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab8d72-2035-486f-8b76-c7a49b85e0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUP_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3a9ad-e4c3-4dce-9afa-dd979beec850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "from pickle import dump, load\n",
    "\n",
    "import torch\n",
    "\n",
    "from gretel_synthetics.timeseries_dgan.dgan import DGAN\n",
    "from gretel_synthetics.timeseries_dgan.config import DGANConfig, OutputType\n",
    "\n",
    "from kafka import KafkaProducer\n",
    "import kafka\n",
    "from time import sleep\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(kafka.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7df8fb2-7d17-4bae-95d3-9dbcb59046a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up DGAN config.\n",
    "\n",
    "config = DGANConfig(\n",
    "    max_sequence_len=720,  # sequence length = 720 time units\n",
    "    sample_len=20,\n",
    "    batch_size=min(1000, 300),\n",
    "    apply_feature_scaling=True,\n",
    "    apply_example_scaling=False,\n",
    "    use_attribute_discriminator=False,\n",
    "    generator_learning_rate=1e-4,\n",
    "    discriminator_learning_rate=1e-4,\n",
    "    epochs=10000,\n",
    ")\n",
    "\n",
    "# initialize a model with this configuration\n",
    "model = DGAN(config)\n",
    "\n",
    "# load in our pretrained model parameters\n",
    "model = model.load(\n",
    "    \"models/dgan_model_5_48_sensors.pt\", map_location=torch.device(\"cpu\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3e66d3-8821-444e-bb75-8ff1401f7ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data - this line generates\n",
    "# 1,000 samples of 12 hour slices of data.\n",
    "_, synthetic_features = model.generate_numpy(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fe67a1-3707-4e9c-a1fb-81dd444b0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# four sensor columns to look at : )\n",
    "sensor_cols = [\"sensor_25\", \"sensor_11\", \"sensor_36\", \"sensor_34\"]\n",
    "\n",
    "\n",
    "# plotting function for a single slice\n",
    "def plot_12hr_slice(slice, ind):\n",
    "    col_indices = [23, 10, 34, 32]\n",
    "    for i in range(4):\n",
    "        column = col_indices[i]\n",
    "        label_i = sensor_cols[i]\n",
    "        plt.plot(slice[:, column], label=label_i)\n",
    "    ax = plt.gca()\n",
    "    ax.title.set_text(\"Slice \" + str(ind))\n",
    "    plt.legend(prop={\"size\": 7})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac2f43-aee2-4a4d-88a2-a95de8c2c14f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot 9 random synthetic windows\n",
    "\n",
    "figure = plt.figure(figsize=(10, 10))\n",
    "figure.suptitle(\"Synthetic 12hr Window plots\", fontsize=25, fontweight=\"roman\")\n",
    "\n",
    "for i in range(9):\n",
    "    figure.add_subplot(3, 3, i + 1)\n",
    "    index = np.random.choice(1000)  # choose a random index from our 1,000 samples\n",
    "    sl = synthetic_features[index]  # select the slice from that index\n",
    "    plot_12hr_slice(sl, index)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aec253-c5fe-46a9-8c49-32f7e155b5b0",
   "metadata": {},
   "source": [
    "### Selecting your slice.\n",
    "\n",
    "- Now that we have generated 1,000 slices of random data, it's time for you to choose a single slice.\n",
    "\n",
    "- In the plot above, you can see 9 different plots of slices of data. Above each plot is the slice number. \n",
    "\n",
    "- If you don't like the look of any of the plots in this figure, you can re-run the cell above to see another set of 9 random slices.\n",
    "\n",
    "- Once you see a slice that you like, **enter the corresponding slice number into the cell below where it's marked.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98484220-bad7-4f46-9693-566267b2d9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter your slice number below\n",
    "my_slice_num = 450\n",
    "\n",
    "my_slice = synthetic_features[my_slice_num]\n",
    "\n",
    "# let's plot that slice to make sure we've got it.\n",
    "plot_12hr_slice(my_slice, my_slice_num)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50727ac5-2902-4d28-8cd5-20f56e2d9ad8",
   "metadata": {},
   "source": [
    "### Streaming our sensor data.\n",
    "\n",
    "- We've got our slice of synthetic sensor data selected now.\n",
    "\n",
    "- It's time for us to stream our data 'from the sensor' to our model and our database. \n",
    "\n",
    "- We'll do so using [Apache Kafka](https://kafka.apache.org/) streaming, an open-source distributed event streaming platform. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58e1aad-d628-4a58-a2a3-658fc84ccf66",
   "metadata": {},
   "source": [
    "First we need to add some fake timestamps to our data - let's do that by converting our data slice to a pandas dataframe with a column of timestamps and then convert it back to numpy so we can easily work with it as an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceea23c-eae7-4fca-811f-e2b7e523cdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial time\n",
    "time_0 = np.datetime64(\"2022-09-01 00:00:00\")\n",
    "timestamps_array = np.array(time_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c317bc-0089-460e-83aa-dd8c300a2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 1 minute to initial time array, 719 times\n",
    "for i in range(1, 720):\n",
    "    new_time = [time_0 + np.timedelta64(i, \"m\")]\n",
    "    timestamps_array = np.append(timestamps_array, new_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e95775-0632-4d61-8125-768f41434a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timestamps_array.shape)  # how many timestamps do we have\n",
    "print(timestamps_array[5:10])  # print 5 example timestamps\n",
    "timestamps_array = np.datetime_as_string(\n",
    "    timestamps_array, unit=\"m\"\n",
    ")  # convert to string\n",
    "print(timestamps_array[5:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903806a-a4be-4756-b3fb-7da27013c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the column to the slice we have\n",
    "timestamps_array = np.expand_dims(timestamps_array, 1)\n",
    "print(timestamps_array.shape)\n",
    "print(my_slice.shape)\n",
    "my_slice = np.concatenate((timestamps_array, my_slice), axis=1, dtype=\"object\")\n",
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f838e2-d61c-443d-b4e3-658dea51a6c0",
   "metadata": {},
   "source": [
    "Great, we've got our slice setup with some simulated timestamps. Now it's time to start streaming our data.\n",
    "\n",
    "First let's define how we're going to connect to our kafka cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbd1db-8a26-4e84-b536-8f9ca0fa9dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "KAFKA_BOOTSTRAP_SERVER = \"kafka-cluster-kafka-bootstrap.edge-kafka.svc.cluster.local\"\n",
    "\n",
    "KAFKA_SASL_MECHANISM = os.environ.get(\"KAFKA_SASL_MECHANISM\", \"PLAIN\")\n",
    "KAFKA_SECURITY_PROTOCOL = \"PLAINTEXT\"\n",
    "\n",
    "# SASL username or client ID loaded from the environment variable\n",
    "KAFKA_USERNAME = os.environ.get(\"KAFKA_USERNAME\")\n",
    "\n",
    "# SASL password or client secret loaded from the environment variable\n",
    "KAFKA_PASSWORD = os.environ.get(\"KAFKA_PASSWORD\")\n",
    "\n",
    "# Name of the topic for the producer to send messages.\n",
    "# Consumers will listen to this topic for events.\n",
    "KAFKA_TOPIC = os.environ.get(\"KAFKA_TOPIC\") or \"sensor-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233c264-52fd-4a78-89ba-11f109e40188",
   "metadata": {},
   "source": [
    "Now, it's time to stream the data. Our function here will connect to the kafka cluster, initialize a KafkaProducer object, and then start streaming messages to our topic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cd09d",
   "metadata": {},
   "source": [
    "## WARNING: Don't run these last two cells until the failure prediction app is running and you have pressed the Start Prediction Graph button."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11c37ed-98c7-4472-9b84-f2a0b56b475d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_data(sensor_slice):\n",
    "    # create the producer\n",
    "    producer = KafkaProducer(\n",
    "        bootstrap_servers=[KAFKA_BOOTSTRAP_SERVER],\n",
    "        security_protocol=KAFKA_SECURITY_PROTOCOL,\n",
    "        sasl_plain_username=KAFKA_USERNAME,\n",
    "        sasl_plain_password=KAFKA_PASSWORD,\n",
    "        api_version_auto_timeout_ms=30000,\n",
    "        max_block_ms=900000,\n",
    "        request_timeout_ms=450000,\n",
    "        acks=\"all\",\n",
    "        key_serializer=str.encode,\n",
    "    )\n",
    "\n",
    "    # sending our data 10 rows per second\n",
    "    for row_index in range(0, 720, 10):\n",
    "        # select our 10 rows\n",
    "        ten_rows = sensor_slice[row_index : row_index + 10, :]\n",
    "        # wait a second\n",
    "        sleep(1)\n",
    "        for i in range(10):\n",
    "            one_row = ten_rows[i].tolist()\n",
    "            jsonpayload = json.dumps(\n",
    "                {\n",
    "                    \"timestamp\": one_row[0],\n",
    "                    \"sensor_data\": one_row[1:-1],\n",
    "                    \"machine_status\": one_row[-1],\n",
    "                }\n",
    "            )\n",
    "            producer.send(KAFKA_TOPIC, jsonpayload.encode(\"utf-8\"), key=str(GROUP_ID))\n",
    "    producer.flush()  # Important, especially if message size is small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b549d4-b5a0-4d5c-86a1-9735477035b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "produce_data(my_slice)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
